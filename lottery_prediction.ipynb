{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data file\n",
    "dataframe = pd.read_csv('./data/megasena.csv', header=None, names=['1st', '2nd', '3rd', '4th', '5th', '6th'])\n",
    "dataframe.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1st</th>\n",
       "      <th>2nd</th>\n",
       "      <th>3rd</th>\n",
       "      <th>4th</th>\n",
       "      <th>5th</th>\n",
       "      <th>6th</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    1st   2nd   3rd   4th   5th   6th\n",
       "0  41.0   5.0   4.0  52.0  30.0  33.0\n",
       "1   9.0  39.0  37.0  49.0  43.0  41.0\n",
       "2  36.0  30.0  10.0  11.0  29.0  47.0\n",
       "3   6.0  59.0  42.0  27.0   1.0   5.0\n",
       "4   1.0  19.0  46.0   6.0  16.0   2.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view some data\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define variables\n",
    "\n",
    "## about game\n",
    "game_length = 6\n",
    "game_range = 60\n",
    "\n",
    "## about neural network\n",
    "# how much games to consider while predicting next one\n",
    "seq_length = 10\n",
    "batch_size = 16\n",
    "\n",
    "## about data\n",
    "# how much games is reserved to validation\n",
    "valid_data_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build batches to feed the network\n",
    "def batch_data(past_results):\n",
    "    feature_tensors, target_tensors = [], []\n",
    "    for idx in range(0, len(past_results)-seq_length):\n",
    "        feature_tensors.append( past_results[idx: idx+seq_length] )\n",
    "        target_tensors.append( past_results[idx+seq_length] )\n",
    "    \n",
    "    feature_tensors = torch.tensor(feature_tensors, dtype=torch.float)\n",
    "    target_tensors = torch.tensor(target_tensors, dtype=torch.float)\n",
    "    \n",
    "    return feature_tensors, target_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature and target tensors based on the past results\n",
    "past_results = dataframe.values\n",
    "feature_tensors, target_tensors = batch_data(past_results)\n",
    "\n",
    "# free memory\n",
    "dataframe = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: [2123, 10, 6] \n",
      "\tnumber of sequences:\t 2123 \n",
      "\tseq_length:\t\t 10 \n",
      "\tgame length:\t\t 6\n",
      "\n",
      "Targets shape: [2123, 6] \n",
      "\tnumber of sequences:\t 2123 \n",
      "\tgame length:\t\t 6\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "First feature sequence: \n",
      "tensor([[41.,  5.,  4., 52., 30., 33.],\n",
      "        [ 9., 39., 37., 49., 43., 41.],\n",
      "        [36., 30., 10., 11., 29., 47.],\n",
      "        [ 6., 59., 42., 27.,  1.,  5.],\n",
      "        [ 1., 19., 46.,  6., 16.,  2.],\n",
      "        [19., 40.,  7., 13., 22., 47.],\n",
      "        [56., 38., 21., 20.,  3.,  5.],\n",
      "        [53., 17., 38.,  4., 47., 37.],\n",
      "        [55., 43., 56., 54.,  8., 60.],\n",
      "        [25.,  4., 18., 57., 21., 38.]])\n",
      "\n",
      "Second feature sequence: \n",
      "tensor([[ 9., 39., 37., 49., 43., 41.],\n",
      "        [36., 30., 10., 11., 29., 47.],\n",
      "        [ 6., 59., 42., 27.,  1.,  5.],\n",
      "        [ 1., 19., 46.,  6., 16.,  2.],\n",
      "        [19., 40.,  7., 13., 22., 47.],\n",
      "        [56., 38., 21., 20.,  3.,  5.],\n",
      "        [53., 17., 38.,  4., 47., 37.],\n",
      "        [55., 43., 56., 54.,  8., 60.],\n",
      "        [25.,  4., 18., 57., 21., 38.],\n",
      "        [25., 15., 58., 37., 59., 38.]])\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "The first target must be the same as the last feature in the second sequence\n",
      "\ttarget: \t tensor([25., 15., 58., 37., 59., 38.]) \n",
      "\tfeature:\t tensor([25., 15., 58., 37., 59., 38.])\n",
      "\n",
      "The second target must be the same as the last feature in the third sequence\n",
      "\ttarget: \t tensor([20., 27., 43., 16., 19.,  4.]) \n",
      "\tfeature:\t tensor([20., 27., 43., 16., 19.,  4.])\n"
     ]
    }
   ],
   "source": [
    "## verify if features and targets are correct\n",
    "\n",
    "print(f'Features shape: {list(feature_tensors.shape)} \\n' +\n",
    "      f'\\tnumber of sequences:\\t {feature_tensors.shape[0]} \\n' +\n",
    "      f'\\tseq_length:\\t\\t {feature_tensors.shape[1]} \\n' +\n",
    "      f'\\tgame length:\\t\\t {feature_tensors.shape[2]}')\n",
    "\n",
    "print()\n",
    "\n",
    "print(f'Targets shape: {list(target_tensors.shape)} \\n' +\n",
    "      f'\\tnumber of sequences:\\t {target_tensors.shape[0]} \\n' +\n",
    "      f'\\tgame length:\\t\\t {target_tensors.shape[1]}')\n",
    "\n",
    "print('\\n----------------------------------------------------\\n')\n",
    "\n",
    "print(f'First feature sequence: \\n{feature_tensors[0]}')\n",
    "print()\n",
    "print(f'Second feature sequence: \\n{feature_tensors[1]}')\n",
    "\n",
    "print('\\n----------------------------------------------------\\n')\n",
    "\n",
    "print('The first target must be the same as the last feature in the second sequence')\n",
    "target = target_tensors[0]\n",
    "feature = feature_tensors[1][-1]\n",
    "print(f'\\ttarget: \\t {target} \\n'+\n",
    "      f'\\tfeature:\\t {feature}')\n",
    "assert (target == feature).all()\n",
    "\n",
    "print()\n",
    "\n",
    "print('The second target must be the same as the last feature in the third sequence')\n",
    "target = target_tensors[1]\n",
    "feature = feature_tensors[2][-1]\n",
    "print(f'\\ttarget: \\t {target} \\n'+\n",
    "      f'\\tfeature:\\t {feature}')\n",
    "assert (target == feature).all()\n",
    "\n",
    "# free memory\n",
    "target, feature = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader: 2093 games; 131 batches\n",
      "valid_dataloader: 30 games; 2 batches\n"
     ]
    }
   ],
   "source": [
    "# Create dataloaders for training and validation\n",
    "\n",
    "train_data = TensorDataset(feature_tensors[:-valid_data_size], target_tensors[:-valid_data_size])\n",
    "valid_data = TensorDataset(feature_tensors[-valid_data_size:], target_tensors[-valid_data_size:])\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print('train_dataloader:', len(train_data), 'games;', len(train_dataloader), 'batches')\n",
    "print('valid_dataloader:', len(valid_data), 'games;', len(valid_dataloader), 'batches')\n",
    "\n",
    "# free memory\n",
    "feature_tensors, target_tensors = None, None\n",
    "train_data, valid_data = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network\n",
    "\n",
    "class LotteryPrediction(nn.Module):\n",
    "    def __init__(self, game_size, game_range, hidden_dim, n_layers, dropout=0.5):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.game_size = game_size\n",
    "        self.game_range = game_range\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        ## Define model layers\n",
    "        self.lstm = nn.LSTM(game_size, hidden_dim, n_layers,\n",
    "                            batch_first=True, dropout=dropout)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, game_range)\n",
    "        \n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, nn_input, hidden):\n",
    "        # Get sizes from tensor input\n",
    "        batch_size = nn_input.shape[0]\n",
    "        \n",
    "        # Feed the network\n",
    "        x, hidden = self.lstm(nn_input, hidden)\n",
    "        \n",
    "        # Predict output scores for the network results\n",
    "        x = self.drop(x)\n",
    "        x = x.contiguous().view(-1, self.hidden_dim)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        # reshape into (batch_size, seq_length, output_size)\n",
    "        x = x.view(batch_size, -1, self.game_range)\n",
    "        \n",
    "        # return the predicted number scores and the hidden state\n",
    "        return x[:, -1], hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # Initialize hidden state with zero weights\n",
    "        \n",
    "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        \n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training loop\n",
    "\n",
    "def train(rnn, batch_size, optimizer, criterion, epochs,\n",
    "          train_dataloader, valid_dataloader, clip=5):\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        \n",
    "        ## Perform the training loop\n",
    "        rnn.train()\n",
    "        training_loss = 0\n",
    "        hidden = rnn.init_hidden(batch_size)\n",
    "        for features, targets in train_dataloader:\n",
    "            \n",
    "            # Creating new variables for the hidden state,\n",
    "            # otherwise, we'd backprop through the entire training history\n",
    "            hidden = tuple([each.data for each in hidden])\n",
    "            \n",
    "            # perform forward pass\n",
    "            out, hidden = rnn(features, hidden)\n",
    "            \n",
    "            # perform backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(out, targets)\n",
    "            loss.backward()\n",
    "            \n",
    "            # prevents the exploding gradient problem\n",
    "            nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n",
    "            \n",
    "            # optimize the gradients\n",
    "            optimizer.step()\n",
    "            \n",
    "            training_loss += loss.item() * len(features)\n",
    "        \n",
    "        training_loss = training_loss / len(train_dataloader.dataset)\n",
    "        \n",
    "        ## Perform the validation loop\n",
    "        rnn.eval()\n",
    "        validation_loss = 0\n",
    "        hidden = rnn.init_hidden(batch_size)\n",
    "        for features, targets in valid_dataloader:\n",
    "            # Creating new variables for the hidden state\n",
    "            hidden = tuple([each.data for each in hidden])\n",
    "            \n",
    "            # perform forward pass\n",
    "            out, hidden = rnn(features, hidden)\n",
    "            \n",
    "            # calculate the validation loss\n",
    "            loss = criterion(out, targets)\n",
    "            \n",
    "            validation_loss += loss.item() * len(features)\n",
    "            \n",
    "        validation_loss = validation_loss / len(valid_dataloader.dataset)\n",
    "        \n",
    "        ## Print results\n",
    "        print(f'Epoch: {epoch:3d}/{epochs:3d} \\t' +\n",
    "              f'Training loss: {training_loss:2.6f} \\t' +\n",
    "              f'Validation loss: {validation_loss:2.6f}')\n",
    "        \n",
    "    return rnn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
